variables {
  time_window_days = "30"
}

cache {
  table_storage_metrics {
    query = "SELECT * FROM snowflake.account_usage.table_storage_metrics"
  }
  
  storage_usage {
    query = "SELECT * FROM snowflake.account_usage.storage_usage"
  }
  
  database_storage_usage_history {
    query = "SELECT * FROM snowflake.account_usage.database_storage_usage_history"
  }
}

checks {
  "Duplicate tables" = {
    description = "If Time Travel is enabled for a table and drop/create or replace table is run on that table, Snowflake will retain the data for the replaced or recreated table that is now deleted. This can become an issue if drop/create or replace is run as part of a scheduled or automated job, causing excessive storage to be used. This rule will identify duplicate tables and show their storage usage."
    severity = INFO
    query = """SELECT
                 table_catalog AS "Database Name",
                 table_name AS "Table Name",
                 COUNT(*) AS "Table Count",
                 SUM(time_travel_bytes) / POWER(1024, 3) AS "Time Travel Storage GB",
                 SUM(active_bytes) / POWER(1024, 3) AS "Active Storage GB"
               FROM
                 table_storage_metrics
               WHERE
                 time_travel_bytes > 0
                 OR active_bytes > 0
               GROUP BY
                 table_name,
                 table_schema,
                 table_catalog
               HAVING
                 "Table Count" > 1
               ORDER BY "Active Storage GB" DESC;"""   
    cache = table_storage_metrics        
    tags = [STORAGE]
  }

  "Storage usage by day" = {
    description = "Storage usage total (in GB) by day over the last {{ time_window_days }} days"
    query = """SELECT
                 DATE_TRUNC('DAY', usage_date) AS "Date",
                 SUM(failsafe_bytes + storage_bytes + stage_bytes) / POWER(1024, 3) AS "Storage GB"
               FROM
                 storage_usage
               WHERE
                 usage_date >= TO_VARCHAR(
                   DATE_TRUNC(
                     'DAY',
                     DATEADD('DAY', - {{ time_window_days }}, CURRENT_TIMESTAMP())
                   ),
                   'YYYY-MM-DD'
                 )
               GROUP BY
                 1
               ORDER BY
                 1 DESC;"""
    cache = storage_usage
    severity = INFO
    tags = [STORAGE]
    graph = {
      title = "Storage usage by day",
      type = "area",
      x = { field = "Date", type = "temporal", labels = "true", timeUnit = "yearmonthdate" },
      y = {
        field = "Storage GB",
        type = "quantitative",
        labels = "true"
      }
    }  
  }

  "Table storage and data protection ratios" = {
    description = "Table storage (GB) and its high ratio of data protection (%) summarized by active, time travel, fail safe, and cloned storage"
    query = """WITH storage_metrics AS (
                 SELECT
                   SUM(active_bytes) AS active_bytes_sum,
                   SUM(time_travel_bytes) AS time_travel_bytes_sum,
                   SUM(failsafe_bytes) AS failsafe_bytes_sum,
                   SUM(retained_for_clone_bytes) AS cloned_bytes_sum,
                   (
                     active_bytes_sum + time_travel_bytes_sum + failsafe_bytes_sum + cloned_bytes_sum
                   ) AS total_bytes
                 FROM
                   table_storage_metrics
               ),
               storage_data_protection_metrics AS (
                 SELECT
                   active_bytes_sum / POWER(1024, 3) AS "Active GB",
                   time_travel_bytes_sum / POWER(1024, 3) AS "Time Travel GB",
                   failsafe_bytes_sum / POWER(1024, 3) AS "Fail Safe GB",
                   cloned_bytes_sum / POWER(1024, 3) AS "Cloned GB",
                   (active_bytes_sum / total_bytes * 100) :: FLOAT AS "Active %",
                   (time_travel_bytes_sum / total_bytes * 100) :: FLOAT AS "Time Travel %",
                   (failsafe_bytes_sum / total_bytes * 100) :: FLOAT AS "Fail Safe %",
                   (cloned_bytes_sum / total_bytes * 100) :: FLOAT AS "Cloned %"
                 FROM
                   storage_metrics
               )
               SELECT
                 *
               FROM
                 storage_data_protection_metrics UNPIVOT(
                   "Value" FOR "Metric" IN (
                     "Active GB",
                     "Active %",
                     "Time Travel GB",
                     "Time Travel %",
                     "Fail Safe GB",
                     "Fail Safe %",
                     "Cloned GB",
                     "Cloned %"
                   )
                 );"""
    cache = table_storage_metrics
    severity = INFO
    tags = [STORAGE]
  }

  "Empty tables using data protection storage" = {
    description = "Tables that are empty but have a high amount of data protection storage"
    query = """SELECT
                 table_catalog || '.' || table_schema || '.' || table_name AS "Table Name",
                 time_travel_bytes / POWER(1024, 3) AS "Time Travel GB",
                 failsafe_bytes / POWER(1024, 3) AS "Fail Safe GB",
                 (time_travel_bytes + failsafe_bytes) / POWER(1024, 3) AS "Data Protection GB"
               FROM
                 table_storage_metrics
               WHERE
                 deleted = false
                 AND active_bytes = 0
                 AND "Data Protection GB" > 1
               ORDER BY
                 "Data Protection GB" DESC
               LIMIT
                 500;"""
    cache = table_storage_metrics
    severity = INFO
    tags = [STORAGE]
  }

  "Unused tables" = {
    description = "Tables not queried within the past {{time_window_days}} days."
    query = """WITH not_deleted_tables_sizes AS (
                 SELECT
                   id AS table_id,
                   (
                     active_bytes + time_travel_bytes + failsafe_bytes + retained_for_clone_bytes
                   ) / POWER(1024, 3) AS total_storage_gb
                 FROM
                   table_storage_metrics
                 WHERE
                   NOT deleted
               ),
               tables_access_history AS (
                 SELECT
                   OBJS_JSON.VALUE:objectId :: TEXT AS table_id,
                   OBJS_JSON.VALUE:objectName :: TEXT AS table_name,
                   MAX(_AH.query_start_time) AS last_queried
                 FROM
                   snowflake.account_usage.access_history _AH,
                   LATERAL FLATTEN(_AH.base_objects_accessed) AS OBJS_JSON
                 WHERE
                   // not secure views 
                   OBJS_JSON.VALUE:objectDomain = 'Table' 
                   // not from data shares
                   AND table_id IS NOT NULL
                 GROUP BY
                   1,
                   2
                 HAVING
                   last_queried < DATEADD('DAY', - {{time_window_days}}, CURRENT_TIMESTAMP())
               )
               SELECT
                 AH.table_id AS "Table ID",
                 AH.table_name AS "Table Name",
                 AH.last_queried AS "Last Queried",
                 SIZES.total_storage_gb AS "Total Storage GB"
               FROM
                 tables_access_history AH
                 INNER JOIN not_deleted_tables_sizes SIZES ON SIZES.table_id = AH.table_id
               ORDER BY
                 SIZES.total_storage_gb DESC;"""
    cache = table_storage_metrics
    severity = INFO
    tags = [STORAGE]
  }

  "Database storage usage" = {
    description = "Database storage usage total (in GB) as of yesterday"
    query = """SELECT
                 database_name AS "Database Name",
                 SUM(average_database_bytes) / POWER(1024, 3) AS "Total Storage GB"
               FROM
                 database_storage_usage_history
               WHERE
                 usage_date = CURRENT_DATE() - 1
               GROUP BY
                 database_name
               ORDER BY
                 "Total Storage GB" DESC;"""
    cache = database_storage_usage_history
    severity = INFO
    tags = [STORAGE]
  }
  
  "Storage trend analysis" = {
    description = "Provides an overview of the daily storage trends within the Snowflake account. It calculates and presents the net addition of data in GB for each day"
    query = """SELECT
                 usage_date AS "Date",
                 COALESCE(
                   (
                     SUM(average_database_bytes) - LAG(SUM(average_database_bytes)) OVER (
                       ORDER BY
                         "Date"
                     )
                   ) / POWER(1024, 3),
                   SUM(average_database_bytes) / POWER(1024, 3)
                 ) AS "Net Addition GB"
               FROM
                 database_storage_usage_history
               WHERE
                 usage_date > DATEADD('DAY', - {{time_window_days}}, CURRENT_TIMESTAMP())
               GROUP BY
                 "Date"
               ORDER BY
                 "Date" DESC;"""
    cache = database_storage_usage_history
    severity = INFO
    tags = [STORAGE]
    graph = {
      title = "Storage trend analysis",
      type = "area",
      x = { field = "Date", type = "temporal", labels = "true", timeUnit = "yearmonthdate" },
      y = {
        field = "Net Addition GB",
        type = "quantitative",
        labels = "true"
      }
    }
  }
}
